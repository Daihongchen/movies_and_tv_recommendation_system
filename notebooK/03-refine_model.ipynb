{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D,  Dropout, Dense, Activation, BatchNormalization, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.applications import vgg16, inception_v3, resnet50, mobilenet\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data_file = '../data/2018_movie_links.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018 = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018 = data_2018.drop(['Unnamed: 0', 'verified', 'rank', 'also_buy', 'also_view', 'details'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018 = data_2018.rename(columns={'overall':'rating', 'asin':'movieID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_count = data_2018.groupby('reviewerID')['rating'].count()\n",
    "product_count = data_2018.groupby('movieID')['rating'].count()\n",
    "average_rating = data_2018.groupby('movieID')['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reviewers that has only one review.\n",
    "data_2018_1 = data_2018.merge(reviewer_count, on='reviewerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018_1 = data_2018_1.rename(columns={'rating_y':'reviewer_count', 'rating_x':'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018_1 = data_2018_1.merge(product_count, on='movieID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018_1 = data_2018_1.rename(columns={'rating_y':'movie_count', 'rating_x':'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018_1 = data_2018_1.merge(average_rating, on='movieID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018_1 = data_2018_1.rename(columns={'rating_y':'average_rating', 'rating_x':'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>description</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>links</th>\n",
       "      <th>reviewer_count</th>\n",
       "      <th>movie_count</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>04 8, 2018</td>\n",
       "      <td>A1CW3NLH9MBQRY</td>\n",
       "      <td>6303022901</td>\n",
       "      <td>{'Format:': ' DVD'}</td>\n",
       "      <td>Sally Nunez</td>\n",
       "      <td>I really enjoyed this movie. Brings tears to m...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1523145600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Genre for Featured Categories...</td>\n",
       "      <td>The Joy Luck Club VHS</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>['Produced by Academy Award(R)-winning filmmak...</td>\n",
       "      <td>Tamlyn Tomita</td>\n",
       "      <td>$3.28</td>\n",
       "      <td>https://www.amazon.com/product-reviews/6303022...</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>04 2, 2018</td>\n",
       "      <td>A1WK0IRZ08NX9X</td>\n",
       "      <td>6303022901</td>\n",
       "      <td>{'Format:': ' DVD'}</td>\n",
       "      <td>Ammie28</td>\n",
       "      <td>If you have never seen this movie, you may jus...</td>\n",
       "      <td>Heart Touching...</td>\n",
       "      <td>1522627200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Genre for Featured Categories...</td>\n",
       "      <td>The Joy Luck Club VHS</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>['Produced by Academy Award(R)-winning filmmak...</td>\n",
       "      <td>Tamlyn Tomita</td>\n",
       "      <td>$3.28</td>\n",
       "      <td>https://www.amazon.com/product-reviews/6303022...</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>03 30, 2018</td>\n",
       "      <td>A2HGXJQCQTXE4E</td>\n",
       "      <td>6303022901</td>\n",
       "      <td>{'Format:': ' Blu-ray'}</td>\n",
       "      <td>Pa nhia lee</td>\n",
       "      <td>awesome all time fave movie.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1522368000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Genre for Featured Categories...</td>\n",
       "      <td>The Joy Luck Club VHS</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>['Produced by Academy Award(R)-winning filmmak...</td>\n",
       "      <td>Tamlyn Tomita</td>\n",
       "      <td>$3.28</td>\n",
       "      <td>https://www.amazon.com/product-reviews/6303022...</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>03 30, 2018</td>\n",
       "      <td>A14ASTA78EK120</td>\n",
       "      <td>6303022901</td>\n",
       "      <td>{'Format:': ' DVD'}</td>\n",
       "      <td>lalush</td>\n",
       "      <td>The greatest movie ever!!!!!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1522368000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Genre for Featured Categories...</td>\n",
       "      <td>The Joy Luck Club VHS</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>['Produced by Academy Award(R)-winning filmmak...</td>\n",
       "      <td>Tamlyn Tomita</td>\n",
       "      <td>$3.28</td>\n",
       "      <td>https://www.amazon.com/product-reviews/6303022...</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>03 29, 2018</td>\n",
       "      <td>A2EGT1RXKVOXTJ</td>\n",
       "      <td>6303022901</td>\n",
       "      <td>{'Format:': ' Amazon Video'}</td>\n",
       "      <td>Karin</td>\n",
       "      <td>Love this movie</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1522281600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Genre for Featured Categories...</td>\n",
       "      <td>The Joy Luck Club VHS</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>['Produced by Academy Award(R)-winning filmmak...</td>\n",
       "      <td>Tamlyn Tomita</td>\n",
       "      <td>$3.28</td>\n",
       "      <td>https://www.amazon.com/product-reviews/6303022...</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating   reviewTime      reviewerID     movieID  \\\n",
       "0     5.0   04 8, 2018  A1CW3NLH9MBQRY  6303022901   \n",
       "1     5.0   04 2, 2018  A1WK0IRZ08NX9X  6303022901   \n",
       "2     5.0  03 30, 2018  A2HGXJQCQTXE4E  6303022901   \n",
       "3     5.0  03 30, 2018  A14ASTA78EK120  6303022901   \n",
       "4     5.0  03 29, 2018  A2EGT1RXKVOXTJ  6303022901   \n",
       "\n",
       "                          style reviewerName  \\\n",
       "0           {'Format:': ' DVD'}  Sally Nunez   \n",
       "1           {'Format:': ' DVD'}      Ammie28   \n",
       "2       {'Format:': ' Blu-ray'}  Pa nhia lee   \n",
       "3           {'Format:': ' DVD'}       lalush   \n",
       "4  {'Format:': ' Amazon Video'}       Karin    \n",
       "\n",
       "                                          reviewText            summary  \\\n",
       "0  I really enjoyed this movie. Brings tears to m...         Five Stars   \n",
       "1  If you have never seen this movie, you may jus...  Heart Touching...   \n",
       "2                       awesome all time fave movie.         Five Stars   \n",
       "3                       The greatest movie ever!!!!!         Five Stars   \n",
       "4                                    Love this movie         Five Stars   \n",
       "\n",
       "   unixReviewTime  vote                                           category  \\\n",
       "0      1523145600   NaN  ['Movies & TV', 'Genre for Featured Categories...   \n",
       "1      1522627200   NaN  ['Movies & TV', 'Genre for Featured Categories...   \n",
       "2      1522368000   NaN  ['Movies & TV', 'Genre for Featured Categories...   \n",
       "3      1522368000   NaN  ['Movies & TV', 'Genre for Featured Categories...   \n",
       "4      1522281600   NaN  ['Movies & TV', 'Genre for Featured Categories...   \n",
       "\n",
       "                   title     main_cat  \\\n",
       "0  The Joy Luck Club VHS  Movies & TV   \n",
       "1  The Joy Luck Club VHS  Movies & TV   \n",
       "2  The Joy Luck Club VHS  Movies & TV   \n",
       "3  The Joy Luck Club VHS  Movies & TV   \n",
       "4  The Joy Luck Club VHS  Movies & TV   \n",
       "\n",
       "                                         description          brand  price  \\\n",
       "0  ['Produced by Academy Award(R)-winning filmmak...  Tamlyn Tomita  $3.28   \n",
       "1  ['Produced by Academy Award(R)-winning filmmak...  Tamlyn Tomita  $3.28   \n",
       "2  ['Produced by Academy Award(R)-winning filmmak...  Tamlyn Tomita  $3.28   \n",
       "3  ['Produced by Academy Award(R)-winning filmmak...  Tamlyn Tomita  $3.28   \n",
       "4  ['Produced by Academy Award(R)-winning filmmak...  Tamlyn Tomita  $3.28   \n",
       "\n",
       "                                               links  reviewer_count  \\\n",
       "0  https://www.amazon.com/product-reviews/6303022...               3   \n",
       "1  https://www.amazon.com/product-reviews/6303022...               4   \n",
       "2  https://www.amazon.com/product-reviews/6303022...               4   \n",
       "3  https://www.amazon.com/product-reviews/6303022...               3   \n",
       "4  https://www.amazon.com/product-reviews/6303022...               3   \n",
       "\n",
       "   movie_count  average_rating  \n",
       "0           21        4.857143  \n",
       "1           21        4.857143  \n",
       "2           21        4.857143  \n",
       "3           21        4.857143  \n",
       "4           21        4.857143  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2018_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018_1 = data_2018_1[data_2018_1['reviewer_count']>1]\n",
    "data_2018_1 = data_2018_1[data_2018_1['movie_count']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116700, 20)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2018_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>description</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>links</th>\n",
       "      <th>reviewer_count</th>\n",
       "      <th>movie_count</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>143214</td>\n",
       "      <td>2.0</td>\n",
       "      <td>04 21, 2018</td>\n",
       "      <td>A3AUTVJ6HA7OO0</td>\n",
       "      <td>B0002VER6A</td>\n",
       "      <td>{'Format:': ' DVD'}</td>\n",
       "      <td>Keith M.</td>\n",
       "      <td>Listed with English Subtitles. It does not hav...</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1524268800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Genre for Featured Categories...</td>\n",
       "      <td>La Mafia De Un Gallero</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>['Starring: Sebastian Ligarde, Eleazar Garcia ...</td>\n",
       "      <td>Socorro Albarran</td>\n",
       "      <td>$3.79</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B0002VE...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175763</td>\n",
       "      <td>5.0</td>\n",
       "      <td>04 1, 2018</td>\n",
       "      <td>AEGZZGMLHEZGX</td>\n",
       "      <td>B0019BI0W4</td>\n",
       "      <td>{'Format:': ' DVD'}</td>\n",
       "      <td>Truent101</td>\n",
       "      <td>Love this show, creepy!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1522540800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Boxed Sets', 'Documentary']</td>\n",
       "      <td>A Haunting Season 4</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>[\"This 3DVD set of the fourth season of A Haun...</td>\n",
       "      <td>Haunting</td>\n",
       "      <td>$10.29</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B0019BI...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175762</td>\n",
       "      <td>5.0</td>\n",
       "      <td>03 31, 2018</td>\n",
       "      <td>A3K4MUNEA7T5Q1</td>\n",
       "      <td>B0019BI0W4</td>\n",
       "      <td>{'Format:': ' DVD'}</td>\n",
       "      <td>Robyn Cano</td>\n",
       "      <td>I like that it tells a lot about what goes on ...</td>\n",
       "      <td>I like that it tells a lot about what goes on ...</td>\n",
       "      <td>1522454400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Boxed Sets', 'Documentary']</td>\n",
       "      <td>A Haunting Season 4</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>[\"This 3DVD set of the fourth season of A Haun...</td>\n",
       "      <td>Haunting</td>\n",
       "      <td>$10.29</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B0019BI...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155016</td>\n",
       "      <td>5.0</td>\n",
       "      <td>05 16, 2018</td>\n",
       "      <td>A3RV0307UNWEEX</td>\n",
       "      <td>B00005JMMT</td>\n",
       "      <td>{'Format:': ' DVD'}</td>\n",
       "      <td>Linda C.</td>\n",
       "      <td>great series.  too bad they did not continue t...</td>\n",
       "      <td>Not the run of the mill cop/firefighter/crime ...</td>\n",
       "      <td>1526428800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Studio Specials', 'Lionsgate ...</td>\n",
       "      <td>Boomtown - Season One</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>['I\\'d say a lot more about NBC, but I don\\'t ...</td>\n",
       "      <td>Donnie Wahlberg</td>\n",
       "      <td>$19.98</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00005J...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129966</td>\n",
       "      <td>5.0</td>\n",
       "      <td>01 30, 2018</td>\n",
       "      <td>A6IDZ37BVM6DJ</td>\n",
       "      <td>B00XZZMTOM</td>\n",
       "      <td>{'Format:': ' DVD'}</td>\n",
       "      <td>george botelho</td>\n",
       "      <td>1</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1517270400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Movies &amp; TV', 'Independently Distributed', '...</td>\n",
       "      <td>I Am Chris Farley</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>[\"I Am Chris Farley is a documentary film that...</td>\n",
       "      <td>Christina Applegate</td>\n",
       "      <td>$5.45</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00XZZM...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating   reviewTime      reviewerID     movieID                style  \\\n",
       "143214     2.0  04 21, 2018  A3AUTVJ6HA7OO0  B0002VER6A  {'Format:': ' DVD'}   \n",
       "175763     5.0   04 1, 2018   AEGZZGMLHEZGX  B0019BI0W4  {'Format:': ' DVD'}   \n",
       "175762     5.0  03 31, 2018  A3K4MUNEA7T5Q1  B0019BI0W4  {'Format:': ' DVD'}   \n",
       "155016     5.0  05 16, 2018  A3RV0307UNWEEX  B00005JMMT  {'Format:': ' DVD'}   \n",
       "129966     5.0  01 30, 2018   A6IDZ37BVM6DJ  B00XZZMTOM  {'Format:': ' DVD'}   \n",
       "\n",
       "          reviewerName                                         reviewText  \\\n",
       "143214        Keith M.  Listed with English Subtitles. It does not hav...   \n",
       "175763       Truent101                            Love this show, creepy!   \n",
       "175762      Robyn Cano  I like that it tells a lot about what goes on ...   \n",
       "155016        Linda C.  great series.  too bad they did not continue t...   \n",
       "129966  george botelho                                                  1   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "143214                                          Two Stars      1524268800   \n",
       "175763                                         Five Stars      1522540800   \n",
       "175762  I like that it tells a lot about what goes on ...      1522454400   \n",
       "155016  Not the run of the mill cop/firefighter/crime ...      1526428800   \n",
       "129966                                         Five Stars      1517270400   \n",
       "\n",
       "        vote                                           category  \\\n",
       "143214   NaN  ['Movies & TV', 'Genre for Featured Categories...   \n",
       "175763   NaN       ['Movies & TV', 'Boxed Sets', 'Documentary']   \n",
       "175762   NaN       ['Movies & TV', 'Boxed Sets', 'Documentary']   \n",
       "155016   NaN  ['Movies & TV', 'Studio Specials', 'Lionsgate ...   \n",
       "129966   NaN  ['Movies & TV', 'Independently Distributed', '...   \n",
       "\n",
       "                         title     main_cat  \\\n",
       "143214  La Mafia De Un Gallero  Movies & TV   \n",
       "175763     A Haunting Season 4  Movies & TV   \n",
       "175762     A Haunting Season 4  Movies & TV   \n",
       "155016   Boomtown - Season One  Movies & TV   \n",
       "129966       I Am Chris Farley  Movies & TV   \n",
       "\n",
       "                                              description  \\\n",
       "143214  ['Starring: Sebastian Ligarde, Eleazar Garcia ...   \n",
       "175763  [\"This 3DVD set of the fourth season of A Haun...   \n",
       "175762  [\"This 3DVD set of the fourth season of A Haun...   \n",
       "155016  ['I\\'d say a lot more about NBC, but I don\\'t ...   \n",
       "129966  [\"I Am Chris Farley is a documentary film that...   \n",
       "\n",
       "                      brand   price  \\\n",
       "143214     Socorro Albarran   $3.79   \n",
       "175763             Haunting  $10.29   \n",
       "175762             Haunting  $10.29   \n",
       "155016      Donnie Wahlberg  $19.98   \n",
       "129966  Christina Applegate   $5.45   \n",
       "\n",
       "                                                    links  reviewer_count  \\\n",
       "143214  https://www.amazon.com/product-reviews/B0002VE...              12   \n",
       "175763  https://www.amazon.com/product-reviews/B0019BI...               2   \n",
       "175762  https://www.amazon.com/product-reviews/B0019BI...               2   \n",
       "155016  https://www.amazon.com/product-reviews/B00005J...               5   \n",
       "129966  https://www.amazon.com/product-reviews/B00XZZM...              16   \n",
       "\n",
       "        movie_count  average_rating  \n",
       "143214            2             2.0  \n",
       "175763            2             5.0  \n",
       "175762            2             5.0  \n",
       "155016            2             5.0  \n",
       "129966            2             5.0  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2018_1.sort_values('movie_count').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode reviewerID and movieID to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35992 20298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "reviewer_enc = LabelEncoder()\n",
    "data_2018_1['reviewer'] = reviewer_enc.fit_transform(data_2018_1['reviewerID'].astype(str).values)\n",
    "n_reviewers = data_2018_1['reviewer'].nunique()\n",
    "movie_enc = LabelEncoder()\n",
    "data_2018_1['movie'] = movie_enc.fit_transform(data_2018_1['movieID'].astype(str).values)\n",
    "n_movies = data_2018_1['movie'].nunique()\n",
    "data_2018_1['rating'] = data_2018_1['rating'].values.astype(np.float32)\n",
    "min_rating = min(data_2018_1['rating'])\n",
    "max_rating = max(data_2018_1['rating'])\n",
    "print(n_reviewers, n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116700, 2), (116700,))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_2018_1[['reviewer','movie']].values\n",
    "y = data_2018_1['rating'].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((93360, 2), (23340, 2), (93360,), (23340,))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Reshape, Dot\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 50\n",
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecommenderV4(n_reviewers, n_movies, n_factors, loss, opt, metrics):\n",
    "    reviewer = Input(shape=(1,))\n",
    "    r = Embedding(n_reviewers, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(reviewer)\n",
    "    r = Reshape((n_factors,))(r)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = Embedding(n_movies, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(movie)\n",
    "    m = Reshape((n_factors,))(m)\n",
    "    \n",
    "    x = Dot(axes=1)([r, m])\n",
    "    model = Model(inputs=[reviewer, movie], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss='mean_squared_error'\n",
    "opt = Adam(lr=0.001)\n",
    "n_factors=50\n",
    "metrics=['mae']\n",
    "\n",
    "model1 = RecommenderV4(n_reviewers, n_movies,n_factors, loss, opt, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/10\n",
      "93360/93360 [==============================] - 28s 303us/sample - loss: 20.0328 - mae: 4.3305 - val_loss: 19.5615 - val_mae: 4.2720\n",
      "Epoch 2/10\n",
      "93360/93360 [==============================] - 34s 365us/sample - loss: 16.2980 - mae: 3.8090 - val_loss: 17.2036 - val_mae: 3.9145\n",
      "Epoch 3/10\n",
      "93360/93360 [==============================] - 35s 370us/sample - loss: 11.7154 - mae: 3.0565 - val_loss: 15.1576 - val_mae: 3.5466\n",
      "Epoch 4/10\n",
      "93360/93360 [==============================] - 31s 330us/sample - loss: 7.9317 - mae: 2.3453 - val_loss: 13.7230 - val_mae: 3.2505\n",
      "Epoch 5/10\n",
      "93360/93360 [==============================] - 28s 295us/sample - loss: 5.1654 - mae: 1.7604 - val_loss: 12.7873 - val_mae: 3.0324\n",
      "Epoch 6/10\n",
      "93360/93360 [==============================] - 28s 295us/sample - loss: 3.2775 - mae: 1.2971 - val_loss: 12.1963 - val_mae: 2.8804\n",
      "Epoch 7/10\n",
      "93360/93360 [==============================] - 28s 299us/sample - loss: 2.0762 - mae: 0.9443 - val_loss: 11.8462 - val_mae: 2.7813\n",
      "Epoch 8/10\n",
      "93360/93360 [==============================] - 27s 290us/sample - loss: 1.3619 - mae: 0.6904 - val_loss: 11.6376 - val_mae: 2.7177\n",
      "Epoch 9/10\n",
      "93360/93360 [==============================] - 28s 297us/sample - loss: 0.9582 - mae: 0.5145 - val_loss: 11.5180 - val_mae: 2.6790\n",
      "Epoch 10/10\n",
      "93360/93360 [==============================] - 30s 323us/sample - loss: 0.7424 - mae: 0.4025 - val_loss: 11.4410 - val_mae: 2.6564\n"
     ]
    }
   ],
   "source": [
    "## base model\n",
    "history = model1.fit(x=X_train_array, \n",
    "                     y=y_train, \n",
    "                     batch_size=64, \n",
    "                     epochs=10,\n",
    "                     verbose=1,\n",
    "                     validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Add, Activation, Lambda\n",
    "class EmbeddingLayer:\n",
    "    def __init__(self, n_items, n_factors):\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = Embedding(self.n_items, self.n_factors, embeddings_initializer='he_normal',\n",
    "                      embeddings_regularizer=l2(1e-6))(x)\n",
    "        x = Reshape((self.n_factors,))(x)\n",
    "        return x\n",
    "def RecommenderV2(n_reviewers, n_movies, n_factors, min_rating, max_rating):\n",
    "    reviewer = Input(shape=(1,))\n",
    "    r = EmbeddingLayer(n_reviewers, n_factors)(reviewer)\n",
    "    rb = EmbeddingLayer(n_reviewers, 1)(reviewer)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_movies, n_factors)(movie)\n",
    "    mb = EmbeddingLayer(n_movies, 1)(movie)\n",
    "    x = Dot(axes=1)([r, m])\n",
    "    x = Add()([x, rb, mb])\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    model = Model(inputs=[reviewer, movie], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 50)        1799600     input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 50)        1014900     input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 50)           0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 50)           0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 1)         35992       input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 1)         20298       input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_9 (Dot)                     (None, 1)            0           reshape_18[0][0]                 \n",
      "                                                                 reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 1)            0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 1)            0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1)            0           dot_9[0][0]                      \n",
      "                                                                 reshape_19[0][0]                 \n",
      "                                                                 reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           activation[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,870,790\n",
      "Trainable params: 2,870,790\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RecommenderV2(n_reviewers, n_movies, n_factors, min_rating, max_rating)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daihongchen/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Users/daihongchen/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93360/93360 [==============================] - 30s 324us/sample - loss: 3.0171 - mae: 1.6461 - val_loss: 2.7039 - val_mae: 1.5517\n",
      "Epoch 2/10\n",
      "93360/93360 [==============================] - 30s 323us/sample - loss: 2.1191 - mae: 1.3370 - val_loss: 2.0698 - val_mae: 1.3099\n",
      "Epoch 3/10\n",
      "93360/93360 [==============================] - 28s 304us/sample - loss: 1.2278 - mae: 0.9447 - val_loss: 1.7030 - val_mae: 1.1310\n",
      "Epoch 4/10\n",
      "93360/93360 [==============================] - 27s 287us/sample - loss: 0.6861 - mae: 0.6473 - val_loss: 1.5208 - val_mae: 1.0205\n",
      "Epoch 5/10\n",
      "93360/93360 [==============================] - 26s 281us/sample - loss: 0.4043 - mae: 0.4496 - val_loss: 1.4284 - val_mae: 0.9525\n",
      "Epoch 6/10\n",
      "93360/93360 [==============================] - 29s 307us/sample - loss: 0.2707 - mae: 0.3268 - val_loss: 1.3757 - val_mae: 0.9075\n",
      "Epoch 7/10\n",
      "93360/93360 [==============================] - 26s 277us/sample - loss: 0.2105 - mae: 0.2544 - val_loss: 1.3391 - val_mae: 0.8768\n",
      "Epoch 8/10\n",
      "93360/93360 [==============================] - 26s 276us/sample - loss: 0.1835 - mae: 0.2144 - val_loss: 1.3053 - val_mae: 0.8524\n",
      "Epoch 9/10\n",
      "93360/93360 [==============================] - 29s 308us/sample - loss: 0.1716 - mae: 0.1952 - val_loss: 1.2725 - val_mae: 0.8344\n",
      "Epoch 10/10\n",
      "93360/93360 [==============================] - 28s 302us/sample - loss: 0.1656 - mae: 0.1872 - val_loss: 1.2346 - val_mae: 0.8167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_array, \n",
    "                    y=y_train, \n",
    "                    batch_size=64, \n",
    "                    epochs=10,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add layers to model as deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout\n",
    "def RecommenderNet(n_reviewers, n_movies, n_factors, min_rating, max_rating):\n",
    "    reviewer = Input(shape=(1,))\n",
    "    r = EmbeddingLayer(n_reviewers, n_factors)(reviewer)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_movies, n_factors)(movie)\n",
    "    \n",
    "    x = Concatenate()([r, m])\n",
    "    x = Dropout(0.05)(x)\n",
    "    \n",
    "    x = Dense(10, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(10, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    model = Model(inputs=[reviewer, movie], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_36 (Embedding)        (None, 1, 50)        1799600     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 1, 50)        1014900     input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_36 (Reshape)            (None, 50)           0           embedding_36[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_37 (Reshape)            (None, 50)           0           embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 100)          0           reshape_36[0][0]                 \n",
      "                                                                 reshape_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 100)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           1010        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 10)           0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           110         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 10)           0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            11          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           activation_7[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,815,631\n",
      "Trainable params: 2,815,631\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = RecommenderNet(n_reviewers, n_movies, n_factors, min_rating, max_rating)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/15\n",
      "93360/93360 [==============================] - 29s 305us/sample - loss: 0.1556 - mae: 0.1835 - val_loss: 1.1317 - val_mae: 0.7741\n",
      "Epoch 2/15\n",
      "93360/93360 [==============================] - 29s 308us/sample - loss: 0.1509 - mae: 0.1788 - val_loss: 1.1040 - val_mae: 0.7614\n",
      "Epoch 3/15\n",
      "93360/93360 [==============================] - 29s 306us/sample - loss: 0.1479 - mae: 0.1767 - val_loss: 1.0798 - val_mae: 0.7507\n",
      "Epoch 4/15\n",
      "93360/93360 [==============================] - 29s 314us/sample - loss: 0.1457 - mae: 0.1759 - val_loss: 1.0574 - val_mae: 0.7402\n",
      "Epoch 5/15\n",
      "93360/93360 [==============================] - 29s 307us/sample - loss: 0.1434 - mae: 0.1746 - val_loss: 1.0367 - val_mae: 0.7304\n",
      "Epoch 6/15\n",
      "93360/93360 [==============================] - 29s 307us/sample - loss: 0.1416 - mae: 0.1738 - val_loss: 1.0181 - val_mae: 0.7215\n",
      "Epoch 7/15\n",
      "93360/93360 [==============================] - 28s 303us/sample - loss: 0.1396 - mae: 0.1728 - val_loss: 1.0010 - val_mae: 0.7131\n",
      "Epoch 8/15\n",
      "93360/93360 [==============================] - 30s 322us/sample - loss: 0.1380 - mae: 0.1720 - val_loss: 0.9851 - val_mae: 0.7053\n",
      "Epoch 9/15\n",
      "93360/93360 [==============================] - 27s 293us/sample - loss: 0.1366 - mae: 0.1716 - val_loss: 0.9704 - val_mae: 0.6976\n",
      "Epoch 10/15\n",
      "93360/93360 [==============================] - 30s 321us/sample - loss: 0.1351 - mae: 0.1707 - val_loss: 0.9576 - val_mae: 0.6907\n",
      "Epoch 11/15\n",
      "93360/93360 [==============================] - 30s 324us/sample - loss: 0.1338 - mae: 0.1702 - val_loss: 0.9447 - val_mae: 0.6841\n",
      "Epoch 12/15\n",
      "93360/93360 [==============================] - 30s 323us/sample - loss: 0.1326 - mae: 0.1694 - val_loss: 0.9340 - val_mae: 0.6782\n",
      "Epoch 13/15\n",
      "93360/93360 [==============================] - 30s 325us/sample - loss: 0.1316 - mae: 0.1689 - val_loss: 0.9235 - val_mae: 0.6725\n",
      "Epoch 14/15\n",
      "93360/93360 [==============================] - 30s 322us/sample - loss: 0.1305 - mae: 0.1683 - val_loss: 0.9139 - val_mae: 0.6671\n",
      "Epoch 15/15\n",
      "93360/93360 [==============================] - 29s 315us/sample - loss: 0.1296 - mae: 0.1679 - val_loss: 0.9050 - val_mae: 0.6618\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_array, \n",
    "                    y=y_train, \n",
    "                    batch_size=64, \n",
    "                    epochs=15,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout, Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "def RecommenderNet_2(n_reviewers, n_movies, n_factors, min_rating, max_rating):\n",
    "    reviewer = Input(shape=(1,))\n",
    "    r = EmbeddingLayer(n_reviewers, n_factors)(reviewer)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_movies, n_factors)(movie)\n",
    "    \n",
    "    x = Concatenate()([r, m])\n",
    "    x = Dropout(0.05)(x)\n",
    "    \n",
    "    x = Dense(10, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(10, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    model = Model(inputs=[reviewer, movie], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_57 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_58 (Embedding)        (None, 1, 50)        1799600     input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_59 (Embedding)        (None, 1, 50)        1014900     input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_58 (Reshape)            (None, 50)           0           embedding_58[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_59 (Reshape)            (None, 50)           0           embedding_59[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 100)          0           reshape_58[0][0]                 \n",
      "                                                                 reshape_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 100)          0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 10)           1010        dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 10)           0           dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 10)           0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 10)           110         dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 10)           0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 10)           0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 10)           0           dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 10)           0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 1)            11          dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1)            0           dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1)            0           activation_38[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,815,631\n",
      "Trainable params: 2,815,631\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = RecommenderNet_2(n_reviewers, n_movies, n_factors, min_rating, max_rating)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daihongchen/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Users/daihongchen/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93360/93360 [==============================] - 28s 304us/sample - loss: 1.5389 - mae: 0.9255 - val_loss: 0.9528 - val_mae: 0.6147\n",
      "Epoch 2/15\n",
      "93360/93360 [==============================] - 28s 305us/sample - loss: 0.9522 - mae: 0.6077 - val_loss: 0.8948 - val_mae: 0.5132\n",
      "Epoch 3/15\n",
      "93360/93360 [==============================] - 27s 293us/sample - loss: 0.8474 - mae: 0.5366 - val_loss: 0.8827 - val_mae: 0.4990\n",
      "Epoch 4/15\n",
      "93360/93360 [==============================] - 27s 288us/sample - loss: 0.8105 - mae: 0.5103 - val_loss: 0.8888 - val_mae: 0.4974\n",
      "Epoch 5/15\n",
      "93360/93360 [==============================] - 28s 298us/sample - loss: 0.7906 - mae: 0.4964 - val_loss: 0.9014 - val_mae: 0.5061\n",
      "Epoch 6/15\n",
      "93360/93360 [==============================] - 29s 306us/sample - loss: 0.7799 - mae: 0.4882 - val_loss: 0.9076 - val_mae: 0.5050\n",
      "Epoch 7/15\n",
      "93360/93360 [==============================] - 28s 295us/sample - loss: 0.7809 - mae: 0.4858 - val_loss: 0.9226 - val_mae: 0.5230\n",
      "Epoch 8/15\n",
      "93360/93360 [==============================] - 28s 295us/sample - loss: 0.7872 - mae: 0.4886 - val_loss: 0.9295 - val_mae: 0.5153\n",
      "Epoch 9/15\n",
      "93360/93360 [==============================] - 27s 293us/sample - loss: 0.7963 - mae: 0.4906 - val_loss: 0.9383 - val_mae: 0.5132\n",
      "Epoch 10/15\n",
      "93360/93360 [==============================] - 28s 301us/sample - loss: 0.8023 - mae: 0.4937 - val_loss: 0.9435 - val_mae: 0.5193\n",
      "Epoch 11/15\n",
      "93360/93360 [==============================] - 28s 297us/sample - loss: 0.8137 - mae: 0.4985 - val_loss: 0.9498 - val_mae: 0.5331\n",
      "Epoch 12/15\n",
      "93360/93360 [==============================] - 28s 299us/sample - loss: 0.8108 - mae: 0.4957 - val_loss: 0.9518 - val_mae: 0.5277\n",
      "Epoch 13/15\n",
      "93360/93360 [==============================] - 28s 299us/sample - loss: 0.8121 - mae: 0.4970 - val_loss: 0.9601 - val_mae: 0.5454\n",
      "Epoch 14/15\n",
      "93360/93360 [==============================] - 28s 296us/sample - loss: 0.8120 - mae: 0.4959 - val_loss: 0.9533 - val_mae: 0.5277\n",
      "Epoch 15/15\n",
      "93360/93360 [==============================] - 29s 307us/sample - loss: 0.8167 - mae: 0.4992 - val_loss: 0.9552 - val_mae: 0.5387\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(x=X_train_array, \n",
    "                    y=y_train, \n",
    "                    batch_size=64, \n",
    "                    epochs=15,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_60 (Embedding)        (None, 1, 50)        1799600     input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_61 (Embedding)        (None, 1, 50)        1014900     input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_60 (Reshape)            (None, 50)           0           embedding_60[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_61 (Reshape)            (None, 50)           0           embedding_61[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 100)          0           reshape_60[0][0]                 \n",
      "                                                                 reshape_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 100)          0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 10)           1010        dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 10)           0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 10)           0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 10)           110         dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 10)           0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 10)           0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 10)           0           dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 10)           0           flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 1)            11          dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 1)            0           dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           activation_41[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,815,631\n",
      "Trainable params: 2,815,631\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = RecommenderNet_2(n_reviewers, n_movies, n_factors, min_rating, max_rating)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daihongchen/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Users/daihongchen/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93360/93360 [==============================] - 29s 309us/sample - loss: 1.6431 - mae: 0.9976 - val_loss: 1.0048 - val_mae: 0.6805\n",
      "Epoch 2/5\n",
      "93360/93360 [==============================] - 29s 309us/sample - loss: 1.0671 - mae: 0.6856 - val_loss: 0.9235 - val_mae: 0.5548\n",
      "Epoch 3/5\n",
      "93360/93360 [==============================] - 29s 314us/sample - loss: 0.9609 - mae: 0.6008 - val_loss: 0.9082 - val_mae: 0.5235\n",
      "Epoch 4/5\n",
      "93360/93360 [==============================] - 28s 300us/sample - loss: 0.9325 - mae: 0.5792 - val_loss: 0.9071 - val_mae: 0.5132\n",
      "Epoch 5/5\n",
      "93360/93360 [==============================] - 29s 310us/sample - loss: 0.9154 - mae: 0.5639 - val_loss: 0.9097 - val_mae: 0.5103\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(x=X_train_array, \n",
    "                    y=y_train, \n",
    "                    batch_size=64, \n",
    "                    epochs=5,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daihongchen/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_cv = load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23340/23340 [==============================] - 2s 103us/sample - loss: 1.5560 - mae: 0.7739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5560174567329648, 0.7738759]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.evaluate(X_test_array, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cvscores = []\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((93360, 2), (93360,), (23340, 2), (23340,))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/5\n",
      "93360/93360 [==============================] - 54s 580us/sample - loss: 0.9939 - mae: 0.5977 - val_loss: 0.9866 - val_mae: 0.5284\n",
      "Epoch 2/5\n",
      "93360/93360 [==============================] - 54s 580us/sample - loss: 0.9954 - mae: 0.5964 - val_loss: 1.0031 - val_mae: 0.5608\n",
      "Epoch 3/5\n",
      "93360/93360 [==============================] - 53s 572us/sample - loss: 0.9920 - mae: 0.5940 - val_loss: 1.0236 - val_mae: 0.5571\n",
      "Epoch 4/5\n",
      "93360/93360 [==============================] - 54s 579us/sample - loss: 0.9919 - mae: 0.5937 - val_loss: 1.0266 - val_mae: 0.5758\n",
      "Epoch 5/5\n",
      "93360/93360 [==============================] - 54s 579us/sample - loss: 0.9973 - mae: 0.5963 - val_loss: 1.0331 - val_mae: 0.5750\n",
      "23340/23340 [==============================] - 2s 104us/sample - loss: 1.0331 - mae: 0.5750\n",
      "mae 0.57497174\n",
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/5\n",
      "93360/93360 [==============================] - 55s 586us/sample - loss: 1.0314 - mae: 0.6128 - val_loss: 0.9117 - val_mae: 0.4863\n",
      "Epoch 2/5\n",
      "93360/93360 [==============================] - 55s 590us/sample - loss: 1.0226 - mae: 0.6098 - val_loss: 0.9602 - val_mae: 0.5196\n",
      "Epoch 3/5\n",
      "93360/93360 [==============================] - 55s 590us/sample - loss: 1.0181 - mae: 0.6056 - val_loss: 1.0004 - val_mae: 0.5364\n",
      "Epoch 4/5\n",
      "93360/93360 [==============================] - 55s 586us/sample - loss: 1.0159 - mae: 0.6050 - val_loss: 1.0228 - val_mae: 0.5930\n",
      "Epoch 5/5\n",
      "93360/93360 [==============================] - 55s 587us/sample - loss: 1.0186 - mae: 0.6072 - val_loss: 1.0403 - val_mae: 0.5732\n",
      "23340/23340 [==============================] - 3s 121us/sample - loss: 1.0403 - mae: 0.5732\n",
      "mae 0.57323205\n",
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/5\n",
      "93360/93360 [==============================] - 54s 583us/sample - loss: 1.0523 - mae: 0.6269 - val_loss: 0.9372 - val_mae: 0.5180\n",
      "Epoch 2/5\n",
      "93360/93360 [==============================] - 55s 585us/sample - loss: 1.0424 - mae: 0.6211 - val_loss: 0.9680 - val_mae: 0.5348\n",
      "Epoch 3/5\n",
      "93360/93360 [==============================] - 56s 596us/sample - loss: 1.0369 - mae: 0.6202 - val_loss: 1.0091 - val_mae: 0.5555\n",
      "Epoch 4/5\n",
      "93360/93360 [==============================] - 55s 591us/sample - loss: 1.0400 - mae: 0.6230 - val_loss: 1.0299 - val_mae: 0.5821\n",
      "Epoch 5/5\n",
      "93360/93360 [==============================] - 55s 591us/sample - loss: 1.0415 - mae: 0.6236 - val_loss: 1.0476 - val_mae: 0.5949\n",
      "23340/23340 [==============================] - 2s 104us/sample - loss: 1.0476 - mae: 0.5949\n",
      "mae 0.5948964\n",
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/5\n",
      "93360/93360 [==============================] - 55s 589us/sample - loss: 1.0660 - mae: 0.6432 - val_loss: 0.9568 - val_mae: 0.5202\n",
      "Epoch 2/5\n",
      "93360/93360 [==============================] - 54s 575us/sample - loss: 1.0589 - mae: 0.6392 - val_loss: 0.9971 - val_mae: 0.5498\n",
      "Epoch 3/5\n",
      "93360/93360 [==============================] - 54s 583us/sample - loss: 1.0564 - mae: 0.6377 - val_loss: 1.0179 - val_mae: 0.5721\n",
      "Epoch 4/5\n",
      "93360/93360 [==============================] - 53s 563us/sample - loss: 1.0548 - mae: 0.6365 - val_loss: 1.0410 - val_mae: 0.6058\n",
      "Epoch 5/5\n",
      "93360/93360 [==============================] - 55s 587us/sample - loss: 1.0589 - mae: 0.6413 - val_loss: 1.0597 - val_mae: 0.6241\n",
      "23340/23340 [==============================] - 3s 107us/sample - loss: 1.0597 - mae: 0.6241\n",
      "mae 0.62406003\n",
      "Train on 93360 samples, validate on 23340 samples\n",
      "Epoch 1/5\n",
      "93360/93360 [==============================] - 53s 568us/sample - loss: 1.0816 - mae: 0.6582 - val_loss: 0.9752 - val_mae: 0.5438\n",
      "Epoch 2/5\n",
      "93360/93360 [==============================] - 53s 568us/sample - loss: 1.0744 - mae: 0.6533 - val_loss: 1.0090 - val_mae: 0.5637\n",
      "Epoch 3/5\n",
      "93360/93360 [==============================] - 53s 569us/sample - loss: 1.0698 - mae: 0.6502 - val_loss: 1.0324 - val_mae: 0.5929\n",
      "Epoch 4/5\n",
      "93360/93360 [==============================] - 54s 576us/sample - loss: 1.0704 - mae: 0.6513 - val_loss: 1.0533 - val_mae: 0.6182\n",
      "Epoch 5/5\n",
      "93360/93360 [==============================] - 54s 583us/sample - loss: 1.0728 - mae: 0.6542 - val_loss: 1.0674 - val_mae: 0.6115\n",
      "23340/23340 [==============================] - 2s 106us/sample - loss: 1.0674 - mae: 0.6115\n",
      "mae 0.6115439\n",
      "(0.59574085, 0.019952081)\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cvscores = []\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "    X_test_array = [X_test[:, 0], X_test[:, 1]]\n",
    "      # create model\n",
    "    model_cv.fit(x=X_train_array, \n",
    "               y=y_train, \n",
    "               epochs=5, \n",
    "               verbose=1,\n",
    "               validation_data=(X_test_array, y_test))\n",
    "    #evaluate the model\n",
    "    scores = model_cv.evaluate(x=X_test_array, y=y_test, verbose=1)\n",
    "    print(model_cv.metrics_names[1], scores[1])\n",
    "    cvscores.append(scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.59574085, 0.019952081)\n"
     ]
    }
   ],
   "source": [
    "print((numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10927 11458 19433  5131  5000]\n",
      "[5. 5. 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "movie_data = np.array(list(set(data_2018_1.movie)))\n",
    "user = np.array([10000 for i in range(len(movie_data))])\n",
    "predictions = model_cv.predict([user, movie_data])\n",
    "predictions = np.array([a[0] for a in predictions])\n",
    "recommended_movie_ids = (-predictions).argsort()[:5]\n",
    "print(recommended_movie_ids)\n",
    "print(predictions[recommended_movie_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5687</td>\n",
       "      <td>The King's Speech</td>\n",
       "      <td>4.632353</td>\n",
       "      <td>['Movies &amp; TV', 'Blu-ray', 'Movies']</td>\n",
       "      <td>['After the death of his father King George V ...</td>\n",
       "      <td>$5.00</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B003UES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34940</td>\n",
       "      <td>Under the Tuscan Sun VHS</td>\n",
       "      <td>4.973684</td>\n",
       "      <td>['Movies &amp; TV', 'Genre for Featured Categories...</td>\n",
       "      <td>[\"This is a nice condition VHS, ideal for coll...</td>\n",
       "      <td>$14.95</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B0000VD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37254</td>\n",
       "      <td>Guardians of the Galaxy Vol. 1</td>\n",
       "      <td>4.764706</td>\n",
       "      <td>['Movies &amp; TV', 'Blu-ray', 'Movies']</td>\n",
       "      <td>[\"From Marvel the studio that brought you Marv...</td>\n",
       "      <td>$32.47</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B01A9R6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61883</td>\n",
       "      <td>School of Rock VHS</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>['Movies &amp; TV', 'Paramount Home Entertainment'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$15.92</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00018Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64222</td>\n",
       "      <td>The Lost Valentine Hallmark Hall of Fame</td>\n",
       "      <td>4.945946</td>\n",
       "      <td>['Movies &amp; TV', 'Genre for Featured Categories...</td>\n",
       "      <td>[\"During World War II, Navy Lt. Neil Thomas bi...</td>\n",
       "      <td>$8.99</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B004LO0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  average_rating  \\\n",
       "5687                          The King's Speech        4.632353   \n",
       "34940                  Under the Tuscan Sun VHS        4.973684   \n",
       "37254            Guardians of the Galaxy Vol. 1        4.764706   \n",
       "61883                        School of Rock VHS        4.888889   \n",
       "64222  The Lost Valentine Hallmark Hall of Fame        4.945946   \n",
       "\n",
       "                                                category  \\\n",
       "5687                ['Movies & TV', 'Blu-ray', 'Movies']   \n",
       "34940  ['Movies & TV', 'Genre for Featured Categories...   \n",
       "37254               ['Movies & TV', 'Blu-ray', 'Movies']   \n",
       "61883  ['Movies & TV', 'Paramount Home Entertainment'...   \n",
       "64222  ['Movies & TV', 'Genre for Featured Categories...   \n",
       "\n",
       "                                             description   price  \\\n",
       "5687   ['After the death of his father King George V ...   $5.00   \n",
       "34940  [\"This is a nice condition VHS, ideal for coll...  $14.95   \n",
       "37254  [\"From Marvel the studio that brought you Marv...  $32.47   \n",
       "61883                                                NaN  $15.92   \n",
       "64222  [\"During World War II, Navy Lt. Neil Thomas bi...   $8.99   \n",
       "\n",
       "                                                   links  \n",
       "5687   https://www.amazon.com/product-reviews/B003UES...  \n",
       "34940  https://www.amazon.com/product-reviews/B0000VD...  \n",
       "37254  https://www.amazon.com/product-reviews/B01A9R6...  \n",
       "61883  https://www.amazon.com/product-reviews/B00018Y...  \n",
       "64222  https://www.amazon.com/product-reviews/B004LO0...  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend = data_2018_1[data_2018_1['movie'].isin(recommended_movie_ids)]\n",
    "recommend = (recommend[['title', 'average_rating','category', 'description', 'price', 'links']]).drop_duplicates()\n",
    "recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>75301</td>\n",
       "      <td>Lone Survivor [DVD]</td>\n",
       "      <td>10000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78851</td>\n",
       "      <td>Fury 2014</td>\n",
       "      <td>10000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>very good movie, lots of action to keep your a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title  reviewer  rating  \\\n",
       "75301  Lone Survivor [DVD]     10000     5.0   \n",
       "78851            Fury 2014     10000     5.0   \n",
       "\n",
       "                                                 summary  \n",
       "75301                                         Five Stars  \n",
       "78851  very good movie, lots of action to keep your a...  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2018_1[data_2018_1['reviewer']==10000][['title', 'reviewer','rating','summary']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
